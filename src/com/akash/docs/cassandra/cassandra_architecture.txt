=> Spring Repo
https://www.codingame.com/playgrounds/13642/getting-started-with-spring-data-cassandra
https://github.com/lankydan/spring-data-cassandra/tree/master/src/main


=> Java api 
https://github.com/eugenp/tutorials/tree/master/persistence-modules/java-cassandra


https://stackoverflow.com/questions/24949676/difference-between-partition-key-composite-key-and-clustering-key-in-cassandra
https://teddyma.gitbooks.io/learncassandra/content/model/cql_and_data_structure.html
https://docs.datastax.com/en/cassandra/3.0/cassandra/dml/dmlDatabaseInternalsTOC.html
https://www.guru99.com/cassandra-architecture.html
https://www.quora.com/What-is-the-internal-architecture-of-the-Cassandra-database

*** course 
https://academy.datastax.com/user 
user : akash777.sharma@gmail.com
password : India@123



** imagine Cassandra as a giant HashMap
the Partition keys play the role of that key in map,So each query needs to have them specified. 
clustering keys (columns, which are optional) help in further narrowing your query search 

** One table can have only one combination of same partition key and clustering key

https://docs.datastax.com/en/cassandra/3.0/cassandra/dml/dmlWriteUpdate.html

https://stackoverflow.com/questions/36328063/how-to-return-a-custom-object-from-a-spring-data-jpa-group-by-query

https://stackoverflow.com/questions/44448899/spring-data-for-apache-cassandra-converts-java-time-localdatetime-to-utc


==================================================


Cassandra Architechture :

problems in relational DB :
(1) Master slave architechure : replication is done in asynchronous way, so it is low consistency (ACID but not consistent)
(2) Developers need to take care of this master slave architecture logic in code
(3) Data is normalized (3NF), Joins make query slower
(4) Sharding in relational DB is very difficult, 
	-> schema and code design have to take care of that(sharding by user_id then find all users from india)
	-> data movement between shards is done manually
	-> you cannot do joins
(5) Master slave architecture is not Highly available
	-> many times you need to upgrade system configuration
	-> change DB settings


Lessons Learned :
(1) Consistency is not practical
	cassandra gave it up
(2) Manual Sharding and Rebalancing is Hard
	cassandra will take of that, developer dont have to think about adding/removing nodes
(3) Master slave is complex to manage
(4) Scaling up is expensive
	So use commodity hardware
(5) Scatter/Gather is not good
	Denormalize for real time query performance
	Goal is to hit 1 machine


In cassandra
(1) Data is in denormalized form, no joins
(2) Tables are created in a way that supports queries
(3) masterless architecture
(4) sharding is implemented automatically on the basis of partition key

====================================

Apache Cassandra

Fast distributed database
High Availability
Linear Scalability
Predictible performance
No SPOF
Multi-Data center

No Master-slave , no rebalance, no re-election of master

=> data in Hash rings

Consider Cassandra as a gaint Hash Ring where all nodes in cluster are same machine.
Data is partitioned around the ring
Data is replicated to RF=N servers
All nodes hold data and can answer queries(both reads and write)
Location of data is determined by partition key
No master slave/ replica sets
No config servers/zookeper

=> CAP theorem
Cassandra chooses Availability and Partition Tolerance over consistency
cassandra can have multiple data centers on different locations, it is difficult to maintain consistency

=> Replication
Data is replicated automatically on a count of RF
Replication is done asynchronously


=> Consistency Level
per query consistency
ALL, QUORAM, ONE
How many replicas for query to respond OK


When CL=2 and RF=3, and a write query came
write on 2 nodes will be in sync
write on 3rd node will be async


Availability and consistency depends upon CL value
Low value of CL is less consistent and high available
High value of CL is high consistent and less available


=> Multi data center
Typical Usage : client write to local DC, replicas async to other DC
Replication factor per keyspace per datacenter
Data cennters can be physical or logical

The consistency level defaults to ONE for all write and read operations.
quorum = (sum_of_replication_factors / 2) + 1
sum_of_replication_factors = datacenter1_RF + datacenter2_RF + . . . + datacentern_RF


LOCAL_ONE    -- when in multi DC, async replication to other DCs
LOCAL_QUORAM -- when in multi DC, async replication to other DCs

====================================

=> Write Path of cassandra queries :
Writes are written to any node in the cluster(coordinator), 
	that node can decide where to store that data in cluster

When a write occurs, Cassandra stores the data in a structure in memory, the memtable, 
and also appends writes to the commit log on disk.

commit log is append only data structure, it is fast
After writing to commit log and memtable, it returns OK to client (writes are fast)

Every write include a timestamp
All Memtables flushed to disk periodically to sstable
As all memtable write to disk in one go, it is relatively fast

Deletes are special write case, called tombstone
SStable and commit logs are immutable


=> What is an Sstable
What happens when we have too many sstables at disk

Immutable data files for row storage
Every write has a timestamp when it was written
Compaction merges sstables into one
When one column has data in two different sstables, then it takes the latest by timestamp
Easy to take backups as every write has a timestamp


=> Read Path

Similar to write path

When a client connects to a node and issues a read or write request, 
that node serves as the coordinator for that particular client operation.
The job of the coordinator is to act as a proxy between the client application and the nodes (or replicas) 

Read query can be fired on any node acting as a coordinator
Contacts node with requested key

As compaction is running on sstables, so for a read query on a single node
It has to check multiple sstables and merged in memory and get latest by timestamp

When consitency < ALL, then cassandra performs read repair in background (read_repair_chance)


====================================

tableX
((col1 col2) col3 col4) col5


select * from tableX where col1='';	//invalid
select * from tableX where col2='';	//invalid
select * from tableX where col1='' and col2='';		//valid
select * from tableX where col1='' and col2='' and col3='' and col4='';		//valid
select * from tableX where col1='' and col2='' and col4='';		//invalid


Counter column conditions :
-> It cannot be assigned to a column that serves as the primary key or partition key.
-> All non-counter columns must be part of the primary key.
-> A counter column cannot be indexed or deleted.
-> Use update command to decrease or increase its value.


(col1), col2, col3_counter    // invalid
((col1), col2), col3_counter  // valid


====================================

Nested Sorted Map data structure

Database	-- Keyspace
Table		-- column family
primary key	-- row key
column name	-- column name/key
column value	-- column value

	Map<RowKey, SortedMap<ColumnKey, ColumnValue>>

A map gives efficient key lookup, and the sorted nature gives efficient scans. 
The number of column keys is unbounded

Partition key and clustering keys

====================================



